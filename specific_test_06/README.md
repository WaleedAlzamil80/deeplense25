## **Specific Test VI - Foundation Model**  

This folder contains my solution for **Specific Test VI: Foundation Model** of the DeepLense GSoC 2025 project. The task involves pretraining a **Masked Autoencoder (MAE)** on strong lensing images and fine-tuning it for **multi-class classification** and **super-resolution** using **PyTorch**.  

### ğŸ“Œ **Task Overview**  
The test consists of two main parts:  
1. **Pretraining a Masked Autoencoder (MAE)** on **no_sub** samples to learn meaningful feature representations.  
2. **Fine-tuning the MAE**:  
   - For **multi-class classification** (distinguishing between no_sub, cdm, and axion).  
   - For **super-resolution** (upscaling low-resolution images using high-resolution ground truths).  

#### ğŸ“· Sample Images for Each Task
- **Samples for multi-class classification**
   ![Sample Images](assets/classification/classSample.png)
 
- **Samples for super-resolution**
   ![Sample Images](assets/superresolution/superRsample.png)

### ğŸ“‚ **Folder Structure**  
```
specific_test_06/
â”‚â”€â”€ models/                        # ğŸ“‚ Model definitions & weights
â”‚   â”œâ”€â”€ mae.py                      # MAE model
â”‚   â”œâ”€â”€ classifier.py                # Classification model
â”‚   â”œâ”€â”€ super_resolution.py         # Super-Resolution model
â”‚   â”œâ”€â”€ checkpoints/                 # Trained weights
â”‚       â”œâ”€â”€ mae.pth
â”‚       â”œâ”€â”€ classifier.pth
â”‚       â”œâ”€â”€ super_resolution.pth
â”‚
â”‚â”€â”€ scripts/                        # ğŸ“‚ Training & evaluation scripts NOTE the parameters here are hardcoded
â”‚   â”œâ”€â”€ train_mae.py                 # Train MAE
â”‚   â”œâ”€â”€ train_classifier.py          # Train classification model
â”‚   â”œâ”€â”€ train_superresolution.py           # Train super-resolution model
â”‚   â”œâ”€â”€ evaluate.py                  # Compute MSE, SSIM, PSNR, LPIPS # not created yet
â”‚   â”œâ”€â”€ infer.py                     # Run inference on new images # not ready
â”‚   â”œâ”€â”€ infer_01.py                  # Run inference on new images Classification # not ready
â”‚
â”‚â”€â”€ utils/                          # ğŸ“‚ Helper functions
â”‚   â”œâ”€â”€ Dataset.py                    # Data loading & augmentation
â”‚   â”œâ”€â”€ metrics.py                    # SSIM, PSNR, LPIPS calculations
â”‚   â”œâ”€â”€ helpful.py                    # helpful functions that's used alot
â”‚   â”œâ”€â”€ vis.py                        # save plots like pca and tsne
â”‚   â”œâ”€â”€ extract_encoderPart.py        # take parts from the trained mae model to be used for fine-tuning models
â”‚
â”‚â”€â”€ assets/                        # ğŸ“‚ Store evaluation results
â”‚   â”œâ”€â”€ mae/                                   # Images
â”‚   â”œâ”€â”€ classification/                        # Images
â”‚   â”œâ”€â”€ superresolution/                       # Images
â”‚
â”‚â”€â”€ notebooks/                      # ğŸ“‚ Jupyter notebooks
â”‚   â”œâ”€â”€ mae_training.ipynb                     # Training MAE step-by-step
â”‚   â”œâ”€â”€ classification_training.ipynb          # Fine-tuning classifier
â”‚   â”œâ”€â”€ super_resolution_training.ipynb        # Fine-tuning super-resolution
â”‚
â”‚â”€â”€ requirements.txt                 # ğŸ“œ Dependencies
â”‚â”€â”€ README.md                         # ğŸ“œ Project overview
â”‚â”€â”€ .gitignore                        # ğŸš« Ignore large files (checkpoints, datasets)
```

### **Prepate Data for Masked Autoencoder (MAE) Pretraining**  

#### **Input for Encoder**
- **Sample for splitted-image**
   ![Sample Images](assets/mae/splitted_image.png)

- **Sample for masked-image**
   ![Sample Images](assets/mae/masked_image.png)

|------------|-------------|
| ![Masked Image](assets/mae/masked_patches.png) | ![EncoderInput](assets/mae/visible_patches.png) |
|------------|-------------|


### ğŸ›  **Model and Approach**  
#### **1ï¸âƒ£ Masked Autoencoder (MAE) Pretraining**
- **Goal:** Learn a feature representation of strong lensing images.  
- **Architecture:** Vision Transformer (ViT) backbone with a reconstruction head.  
- **Pretraining Loss:** Mean Squared Error (MSE)
- **Optimizer:** AdamW 
- **Batch Size:** *256*
- **Epochs:** *250*

#### **2ï¸âƒ£ Fine-Tuning for Multi-Class Classification**
- **Loss Function:** Cross-Entropy Loss  
- **Optimizer:** AdamW 
- **Batch Size:** *256*
- **Evaluation Metrics:** AUC Score, Accuracy  
- **Epochs:** *250*

#### **3ï¸âƒ£ Fine-Tuning for Super-Resolution**
- **Loss Function:** Mean Squared Error (MSE)
- **Batch Size:** *256*
- **Evaluation Metrics:** MSE, SSIM, PSNR  
- **Epochs:** *200*

### ğŸ“Š **Results**
- I Will add all results and images from assets 

### ğŸš€ **Running the Code**  
1. Open any `*.ipynb` in Jupyter Notebook.  
2. Run all cells to train the models.  
3. Model checkpoints will be saved in `best_mae_model.pth`, `best_finetuned_model.pth`, and `best_superres_model.pth`.  

### ğŸ“¬ **Submission Details**  
This task is part of my DeepLense GSoC 2025 submission.