# Models

This folder contains the trained models and related scripts for classification and super-resolution tasks.

## ðŸ“‚ Structure

### ðŸ”¹ `checkpoints/`
This subfolder contains the saved model weights:
- **`mae.pth`** â€“ Trained **Masked Autoencoder (MAE)** model.
- **`encoder_embedInput.pth`** â€“ Extracted encoder and input embedding from the trained MAE model.
- **`classifier.pth`** â€“ Fine-tuned classifier model.
- **`superresolution_PSNR.pth`** â€“ Fine-tuned Super-resolution model, selected best model based on **Peak Signal-to-Noise Ratio (PSNR)** metric.
- **`superresolution_SSIM.pth`** â€“ Fine-tuned Super-resolution model, selected best model based on **Structural Similarity Index (SSIM)** metric.

### ðŸ”¹ Model Training Workflow

1. **Pretraining with MAE**
   - The **Masked Autoencoder (MAE)** model was trained and saved as `mae.pth`.

2. **Extracting Encoder Blocks & Input Embedding**
   - Using `utils/extract_encoderPart.py`, the encoder blocks and input embedding layer were extracted from `mae.pth`.
   - The extracted components are stored in `encoder_embedInput.pth` used as a base to train the classifier model and the superresolution model.

3. **Fine-tuning for Downstream Tasks**
   - **Classification:** The extracted encoder was fine-tuned to train a classifier (`classifier.pth`).
   - **Super-resolution:** Two separate models were trained using the extracted encoder also:
     - `superresolution_PSNR.pth` â€“ Trained for best **PSNR**.
     - `superresolution_SSIM.pth` â€“ Trained for best **SSIM**.