# **Self-Supervised MAE, Classification, and Super-Resolution Training Pipeline**  
ğŸš€ **A complete deep learning pipeline** for training a **Masked Autoencoder (MAE)**, fine-tuning it for **classification**, and extending it for **super-resolution**. This project **rescales all data to `150x150` using bicubic interpolation** and evaluates upscaling quality using **MSE, PSNR, SSIM, and LPIPS**.  

---

## **ğŸ“Œ Project Overview**  
This repository provides a structured framework for training:  

âœ… **Masked Autoencoder (MAE)** â†’ Self-supervised pretraining using `150x150` images.  
âœ… **Classification Model** â†’ Fine-tuned on MAEâ€™s learned features.  
âœ… **Super-Resolution Model** â†’ Trained to enhance low-resolution images (`75x75 â†’ 150x150`).  
âœ… **Evaluation Metrics** â†’ MSE, PSNR, SSIM, and LPIPS for image quality assessment.  

**Data is first resized to `150x150` using bicubic interpolation** for consistency across tasks.

---

## **ğŸ“‚ Folder Structure**  
```
repo_name/
â”‚â”€â”€ models/                        # ğŸ“‚ Model definitions & weights
â”‚   â”œâ”€â”€ mae.py                      # MAE model
â”‚   â”œâ”€â”€ classifier.py                # Classification model
â”‚   â”œâ”€â”€ super_res.py                 # Super-Resolution model
â”‚   â”œâ”€â”€ checkpoints/                 # Trained weights
â”‚       â”œâ”€â”€ mae.pth
â”‚       â”œâ”€â”€ classifier.pth
â”‚       â”œâ”€â”€ super_res.pth
â”‚
â”‚â”€â”€ scripts/                        # ğŸ“‚ Training & evaluation scripts
â”‚   â”œâ”€â”€ train_mae.py                 # Train MAE
â”‚   â”œâ”€â”€ train_classifier.py          # Train classification model
â”‚   â”œâ”€â”€ train_super_res.py           # Train super-resolution model
â”‚   â”œâ”€â”€ evaluate.py                  # Compute MSE, SSIM, PSNR, LPIPS
â”‚   â”œâ”€â”€ infer.py                      # Run inference on new images
â”‚
â”‚â”€â”€ utils/                          # ğŸ“‚ Helper functions
â”‚   â”œâ”€â”€ dataset_loader.py            # Data loading & augmentation
â”‚   â”œâ”€â”€ metrics.py                   # SSIM, PSNR, LPIPS calculations
â”‚   â”œâ”€â”€ visualization.py              # Plot results, generate heatmaps
â”‚
â”‚â”€â”€ results/                        # ğŸ“‚ Store evaluation results
â”‚   â”œâ”€â”€ sample_outputs/              # Sample images before & after processing
â”‚   â”œâ”€â”€ logs/                        # Training logs
â”‚   â”œâ”€â”€ comparison_metrics.json       # JSON file with evaluation metrics
â”‚
â”‚â”€â”€ notebooks/                      # ğŸ“‚ Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ mae_training.ipynb            # Training MAE step-by-step
â”‚   â”œâ”€â”€ classification_analysis.ipynb # Checking classifier performance
â”‚   â”œâ”€â”€ super_resolution.ipynb        # Fine-tuning super-resolution
â”‚
â”‚â”€â”€ requirements.txt                 # ğŸ“œ Dependencies
â”‚â”€â”€ README.md                         # ğŸ“œ Project overview
â”‚â”€â”€ .gitignore                        # ğŸš« Ignore large files (checkpoints, datasets)
```

---

## **ğŸ“¥ Installation & Setup**  
### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/your_username/repo_name.git
cd repo_name
```

### **2ï¸âƒ£ Create a Virtual Environment (Optional but Recommended)**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ (Optional) Install GPU-Optimized PyTorch**
Check the official **[PyTorch installation guide](https://pytorch.org/get-started/locally/)** for the correct version.

---

## **ğŸš€ Training Workflow**  
### **1ï¸âƒ£ Train the MAE Model (Self-Supervised Learning)**
```bash
python scripts/train_mae.py --epochs 50 --batch_size 32 --lr 3e-4
```
ğŸ›  **This step pretrains the MAE on `150x150` images using masked image modeling.**  

### **2ï¸âƒ£ Train the Classification Model (Fine-Tuning on MAE Features)**
```bash
python scripts/train_classifier.py --epochs 30 --batch_size 32 --lr 1e-4
```
ğŸ›  **This step uses the MAE encoder to classify images.**  

### **3ï¸âƒ£ Train the Super-Resolution Model (`75x75 â†’ 150x150`)**
```bash
python scripts/train_super_res.py --epochs 40 --batch_size 16 --lr 2e-4
```
ğŸ›  **The model learns to upscale images from `75x75` to `150x150`.**  

---

## **ğŸ“Š Evaluation: Comparing Upscaling Quality**
Run **evaluation metrics (MSE, SSIM, PSNR, LPIPS) on test images**:
```bash
python scripts/evaluate.py --input_folder data/test/
```

---

## **ğŸ“Œ Model Architectures**
### **ğŸŸ¢ Masked Autoencoder (MAE)**
- Vision Transformer (ViT) as the encoder.  
- Trained with **masked image modeling**.  
- **Pretrained model used for classification & super-resolution.**

### **ğŸŸ¢ Classification Model**
- Uses **pretrained MAE encoder**.  
- Final classification **MLP head** for `N` classes.  

### **ğŸŸ¢ Super-Resolution Model**
- Uses a **CNN + Transformer-based decoder**.  
- Learns to **upsample low-resolution images**.  

---

## **ğŸ–¼ Sample Results**
| **Method** | **Original** | **Upscaled** | **MSE â†“** | **PSNR â†‘** | **SSIM â†‘** | **LPIPS â†“** |
|------------|-------------|-------------|----------|----------|----------|----------|
| **Bilinear** | ![original](results/sample_outputs/original.png) | ![bilinear](results/sample_outputs/bilinear.png) | 0.0051 | 28.5 | 0.82 | 0.15 |
| **Bicubic** | ![original](results/sample_outputs/original.png) | ![bicubic](results/sample_outputs/bicubic.png) | 0.0039 | 30.2 | 0.87 | 0.10 |
| **Super-Res Model** | ![original](results/sample_outputs/original.png) | ![sr_model](results/sample_outputs/superres.png) | 0.0025 | 33.1 | 0.92 | 0.05 |

---
## **ğŸ“Œ References**
- **Masked Autoencoders (MAE):** [https://arxiv.org/abs/2111.06377](https://arxiv.org/abs/2111.06377)  
- **ViT for Image Classification:** [https://arxiv.org/abs/2010.11929](https://arxiv.org/abs/2010.11929)  
- **SwinIR (Super-Resolution Transformer):** [https://arxiv.org/abs/2108.10257](https://arxiv.org/abs/2108.10257)  

---

## **ğŸ›  Future Improvements**
ğŸ”¹ **Train MAE on more datasets.**  
ğŸ”¹ **Test more super-resolution models (SwinIR, ESRGAN).**  
ğŸ”¹ **Optimize training speed (AMP, mixed precision).**  

---
## **ğŸ¤ Contributing**
1. Fork the repo ğŸ´  
2. Create a feature branch (`git checkout -b feature-branch`)  
3. Commit changes (`git commit -m "Added feature"`)  
4. Push to your branch (`git push origin feature-branch`)  
5. Open a Pull Request! ğŸš€  

---
## **ğŸ“© Contact**
ğŸ“Œ **Author:** Waleed  
ğŸ“Œ **Email:** your_email@example.com  
ğŸ“Œ **GitHub:** [github.com/WaleedAlzamil8)](https://github.com/WaleedAlzamil8)
